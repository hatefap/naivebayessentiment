{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_PATH = 'http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz'\n",
    "DOWNLOADED_FILENAME = 'cornel_sent.tar.gz'\n",
    "random_state = 101\n",
    "\n",
    "# load english stopwords\n",
    "stopword = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_download(url_path):\n",
    "    if not os.path.exists(DOWNLOADED_FILENAME):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url_path, DOWNLOADED_FILENAME)\n",
    "        except Exception as e:\n",
    "            print(f'Can not download the specified file!, URL = {url_path}')\n",
    "            print('try to put file in the current directory of script manually!')\n",
    "            print('Error code: ', e.code)\n",
    "        else:\n",
    "            print('file downloaded correctly from specified URL:', url_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_download(URL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentiment_file():\n",
    "    with tarfile.open(DOWNLOADED_FILENAME, 'r:gz') as f:\n",
    "        tar_names = f.getnames() # tar_names[1] --> 'rt-polaritydata/rt-polarity.neg' tar_names[2] --> 'rt-polaritydata/rt-polarity.pos'\n",
    "        neg_reviews = f.extractfile(tar_names[1])\n",
    "        pos_reviews = f.extractfile(tar_names[2])\n",
    "        \n",
    "        return pos_reviews.readlines(), neg_reviews.readlines()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_reviews, neg_reviews = read_sentiment_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentencelist):\n",
    "    clean_sentences = []\n",
    "    for s in sentencelist:\n",
    "        # s is in form of byte literal so we must decode it as string\n",
    "        sentence = str(s, 'latin-1').lower() # convert sentence to lowercase\n",
    "        sentence = ''.join(c for c in sentence if c not in punctuation) # remove punctuation\n",
    "        word_tokens = nltk.word_tokenize(sentence)\n",
    "        word_tokens = [word for word in word_tokens if word not in stopword] # remove stopwords\n",
    "        clean_sentences.append(' '.join(word_tokens))\n",
    "    \n",
    "    return clean_sentences\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vocab(sentencelist):\n",
    "    vocab = set()\n",
    "    for s in sentencelist:\n",
    "        vocab.update(s.split())\n",
    "    return list(vocab)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = preprocess(pos_reviews + neg_reviews)\n",
    "vocab = extract_vocab(all_reviews)\n",
    "all_labels = [1]*len(pos_reviews) + [0]*len(neg_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(aSentence):\n",
    "    features = {}\n",
    "    words = aSentence.split()\n",
    "    \n",
    "    for v in vocab:\n",
    "        features[v] = math.log(words.count(v) + 1,2)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_reviews, all_labels, test_size=0.1, \n",
    "                                                    random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = nltk.classify.apply_features(feature_func=extract_features,toks=list(zip(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 15 min to train\n",
    "classifier = nltk.NaiveBayesClassifier.train(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(testsentences):\n",
    "    logit = []\n",
    "    for index in range(len(testsentences)):\n",
    "        sentence = testsentences[index]\n",
    "        featureset = extract_features(sentence)\n",
    "        pred = classifier.classify(featureset)\n",
    "        logit.append(pred)\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77       525\n",
      "           1       0.78      0.76      0.77       542\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1067\n",
      "   macro avg       0.77      0.77      0.77      1067\n",
      "weighted avg       0.77      0.77      0.77      1067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
